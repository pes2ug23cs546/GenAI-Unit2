{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4fb83aa",
      "metadata": {},
      "source": [
        "# Student Details\n",
        "\n",
        "**Name:** Shaunak A. Rai\n",
        "\n",
        "**SRN:** PES2UG23CS546\n",
        "\n",
        "**Date:** 26th February 2026\n",
        "\n",
        "**Semester:** VI\n",
        "\n",
        "**Branch:** CSE\n",
        "\n",
        "**Section:** I\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "950b3561",
      "metadata": {},
      "source": [
        "# Unit 2 Assignment: Building a Mixture of Experts (MoE) Router\n",
        "\n",
        "## Objective\n",
        "Build a **Smart Customer Support Router** using a Mixture of Experts (MoE) architecture with the Groq API.\n",
        "\n",
        "The system routes user queries to specialized experts:\n",
        "1. **Technical Expert** — for bug reports and code issues\n",
        "2. **Billing Expert** — for refund/subscription/payment queries\n",
        "3. **General Expert** — fallback for casual conversation\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ba1357c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Groq client ready | Model: llama-3.3-70b-versatile\n"
          ]
        }
      ],
      "source": [
        "%pip install groq python-dotenv --quiet\n",
        "\n",
        "from groq import Groq\n",
        "from dotenv import load_dotenv\n",
        "import os, time\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "MODEL = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "print(f\"Groq client ready | Model: {MODEL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f4c7d0e",
      "metadata": {},
      "source": [
        "## 1. Define the Experts\n",
        "\n",
        "Each expert is defined by a specialized **System Prompt** that shapes the LLM's behavior. All experts use the same base model but behave differently based on their prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "79dc58f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TECHNICAL] temp=0.7 | prompt_len=349 chars\n",
            "[BILLING] temp=0.7 | prompt_len=369 chars\n",
            "[GENERAL] temp=0.7 | prompt_len=251 chars\n"
          ]
        }
      ],
      "source": [
        "MODEL_CONFIG = {\n",
        "    \"technical\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a Senior Technical Support Engineer with deep expertise in software debugging. \"\n",
        "            \"You are rigorous, code-focused, and precise. When a user reports a bug or technical issue, \"\n",
        "            \"analyze the problem systematically, explain what went wrong, and provide concrete code fixes \"\n",
        "            \"or step-by-step debugging instructions. Always include relevant code snippets.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7\n",
        "    },\n",
        "    \"billing\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a Billing Support Specialist. You are empathetic, financially focused, and policy-driven. \"\n",
        "            \"When a user has a billing concern, acknowledge their frustration first, clearly explain the relevant \"\n",
        "            \"company policies, and outline the exact steps to resolve the issue such as refund process, \"\n",
        "            \"escalation path, or account adjustments. Always be reassuring and professional.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7\n",
        "    },\n",
        "    \"general\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a friendly and helpful General Support Agent. You handle casual questions, product inquiries, \"\n",
        "            \"and anything that doesn't fall into technical or billing categories. Be conversational, helpful, \"\n",
        "            \"and guide the user to the right resources if needed.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "}\n",
        "\n",
        "for name, cfg in MODEL_CONFIG.items():\n",
        "    print(f\"[{name.upper()}] temp={cfg['temperature']} | prompt_len={len(cfg['system_prompt'])} chars\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3249e718",
      "metadata": {},
      "source": [
        "## 2. The Router (`route_prompt`)\n",
        "\n",
        "The router uses an LLM call with `temperature=0` to classify the user's intent into one of the expert categories. It returns **only** the category name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "47ee6697",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 'My python script is throwing an IndexError on line 5.'\n",
            "  -> Routed to: [technical]\n",
            "\n",
            "Query: 'I was charged twice for my subscription this month.'\n",
            "  -> Routed to: [billing]\n",
            "\n",
            "Query: 'Hey, what products do you offer?'\n",
            "  -> Routed to: [general]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def route_prompt(user_input):\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a classification engine. Classify the user message into exactly one category: \"\n",
        "                    \"technical, billing, or general. \"\n",
        "                    \"Return ONLY the category name as a single lowercase word. No punctuation, no explanation.\"\n",
        "                )\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=10\n",
        "    )\n",
        "    return response.choices[0].message.content.strip().lower()\n",
        "\n",
        "test_routes = [\n",
        "    \"My python script is throwing an IndexError on line 5.\",\n",
        "    \"I was charged twice for my subscription this month.\",\n",
        "    \"Hey, what products do you offer?\"\n",
        "]\n",
        "\n",
        "for query in test_routes:\n",
        "    category = route_prompt(query)\n",
        "    print(f\"Query: {query!r}\")\n",
        "    print(f\"  -> Routed to: [{category}]\")\n",
        "    print()\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ad160bd",
      "metadata": {},
      "source": [
        "## 3. The Orchestrator (`process_request`)\n",
        "\n",
        "The orchestrator ties everything together:\n",
        "1. Calls `route_prompt` to classify the query\n",
        "2. Selects the matching expert configuration\n",
        "3. Calls the LLM with the expert's system prompt\n",
        "4. Returns the expert's response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e540ae38",
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_request(user_input):\n",
        "    category = route_prompt(user_input)\n",
        "    config = MODEL_CONFIG.get(category, MODEL_CONFIG[\"general\"])\n",
        "\n",
        "    print(f\"[Router]  -> {category.upper()} Expert\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": config[\"system_prompt\"]},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        temperature=config[\"temperature\"],\n",
        "        max_tokens=1024\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "    print(answer)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76851151",
      "metadata": {},
      "source": [
        "## 4. Testing the MoE System\n",
        "\n",
        "### Test 1: Technical Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "088afa78",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Router]  -> TECHNICAL Expert\n",
            "--------------------------------------------------\n",
            "# Step-by-step analysis of the problem:\n",
            "1. The code attempts to access the 6th element of the list `nums` (remember that indexing in Python starts at 0).\n",
            "2. The list `nums` only contains 3 elements: `[1, 2, 3]`.\n",
            "3. **The IndexError occurs because the index 5 is out of range** for the list `nums`, which only has indices 0, 1, and 2.\n",
            "\n",
            "# Fixed solution:\n",
            "```python\n",
            "# Define the list of numbers\n",
            "nums = [1, 2, 3]\n",
            "\n",
            "# Check if the index is within the bounds of the list\n",
            "index = 5\n",
            "if index < len(nums):\n",
            "    print(nums[index])\n",
            "else:\n",
            "    print(f\"Index {index} is out of range for the list.\")\n",
            "```\n",
            "\n",
            "# Explanation of changes:\n",
            "* **Added a check to ensure the index is within the bounds of the list** before attempting to access the element at that index.\n",
            "* Used the `len()` function to get the number of elements in the list.\n",
            "* Provided a message to the user if the index is out of range.\n",
            "\n",
            "# Tests and example uses:\n",
            "* Try running the code with different indices to see how it handles both valid and invalid indices.\n",
            "* Example: `index = 1` should print `2`, while `index = 5` should print `Index 5 is out of range for the list.`\n",
            "\n",
            "Alternatively, if you want to access the last element of the list, you can use the index `-1`:\n",
            "```python\n",
            "print(nums[-1])  # prints 3\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "_ = process_request(\"My python script is throwing an IndexError on line 5. Here is the code: nums = [1,2,3]; print(nums[5])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f098a3",
      "metadata": {},
      "source": [
        "### Test 2: Billing Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d92cf851",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Router]  -> BILLING Expert\n",
            "--------------------------------------------------\n",
            "I'm so sorry to hear that you were charged twice for your subscription this month. I can imagine how frustrating that must be for you, and I'm here to help resolve the issue as quickly as possible.\n",
            "\n",
            "First, I want to assure you that we take situations like this very seriously and are committed to making it right. Our company policy is to provide a full refund for any duplicate charges that may have occurred due to an error on our part.\n",
            "\n",
            "To initiate the refund process, I'll need to verify some information with you. Could you please confirm your subscription details, including the date of the duplicate charge and the amount that was charged? This will help me to locate the issue and process the refund promptly.\n",
            "\n",
            "Once I have this information, I'll be able to provide a refund for the duplicate charge. Please note that refunds typically take 3-5 business days to process, but I'll do my best to expedite the process for you.\n",
            "\n",
            "If you'd like to escalate this issue or have any concerns about the refund process, I can also offer to transfer you to my supervisor or provide a direct contact method for further assistance.\n",
            "\n",
            "In the meantime, I want to reassure you that we're taking steps to prevent this issue from happening again in the future. Your satisfaction is our top priority, and we appreciate your patience and cooperation as we work to resolve this matter.\n",
            "\n",
            "Let's work together to get this resolved for you. Can you please provide the necessary information so I can proceed with the refund?\n"
          ]
        }
      ],
      "source": [
        "time.sleep(2)\n",
        "_ = process_request(\"I was charged twice for my subscription this month. I need a refund immediately.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12603404",
      "metadata": {},
      "source": [
        "### Test 3: General Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f79b6d29",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Router]  -> GENERAL Expert\n",
            "--------------------------------------------------\n",
            "We have a wide range of products across various categories. We offer everything from home and kitchen essentials, to electronics, fashion, and outdoor gear. Whether you're looking for something for yourself or a gift for someone else, we've got you covered.\n",
            "\n",
            "Some of our most popular products include smart home devices, gaming consoles, and high-quality cookware. We also have a great selection of clothing and accessories from top brands, as well as a variety of outdoor equipment for camping, hiking, and more.\n",
            "\n",
            "If you're looking for something specific, I'd be happy to try and help you find it. Alternatively, you can also check out our website, which has a handy search function and categories to browse through. We're always adding new products to our lineup, so be sure to check back often to see what's new!\n",
            "\n",
            "What kind of product are you in the market for? I'm here to help and can give you some recommendations if you need them!\n"
          ]
        }
      ],
      "source": [
        "time.sleep(2)\n",
        "_ = process_request(\"Hey, what kind of products does your company offer?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75bf631a",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Bonus: Tool Use Expert\n",
        "\n",
        "Adding a **Tool Use** expert that intercepts queries asking for real-time data (like crypto prices) and routes them to a mock data-fetching function instead of the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6761e8ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoE v2 with Tool Use ready.\n"
          ]
        }
      ],
      "source": [
        "def mock_fetch_price(asset):\n",
        "    prices = {\n",
        "        \"bitcoin\": 97432.15,\n",
        "        \"ethereum\": 3521.80,\n",
        "        \"dogecoin\": 0.1423,\n",
        "        \"solana\": 189.67,\n",
        "    }\n",
        "    return prices.get(asset.lower())\n",
        "\n",
        "MODEL_CONFIG[\"tool_use\"] = {\n",
        "    \"system_prompt\": \"You are a Data Retrieval Agent. Extract real-time data using tools and present it clearly.\",\n",
        "    \"temperature\": 0.0\n",
        "}\n",
        "\n",
        "def route_prompt_v2(user_input):\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a classification engine. Classify the user message into exactly one category: \"\n",
        "                    \"technical, billing, tool_use, or general. \"\n",
        "                    \"Use 'tool_use' if the user is asking for real-time data like prices, weather, or stocks. \"\n",
        "                    \"Return ONLY the category name as a single lowercase word.\"\n",
        "                )\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=10\n",
        "    )\n",
        "    return response.choices[0].message.content.strip().lower()\n",
        "\n",
        "def process_request_v2(user_input):\n",
        "    category = route_prompt_v2(user_input)\n",
        "    print(f\"[Router]  -> {category.upper()} Expert\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if category == \"tool_use\":\n",
        "        for asset in [\"bitcoin\", \"ethereum\", \"dogecoin\", \"solana\"]:\n",
        "            if asset in user_input.lower():\n",
        "                price = mock_fetch_price(asset)\n",
        "                result = f\"[Tool Fetch] The current price of {asset.title()} is ${price:,.2f} USD.\"\n",
        "                print(result)\n",
        "                return result\n",
        "        print(\"[Tool Fetch] Asset not recognized. Falling back to general expert.\")\n",
        "        category = \"general\"\n",
        "\n",
        "    config = MODEL_CONFIG.get(category, MODEL_CONFIG[\"general\"])\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": config[\"system_prompt\"]},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        temperature=config[\"temperature\"],\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "    print(answer)\n",
        "    return answer\n",
        "\n",
        "print(\"MoE v2 with Tool Use ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e3b870",
      "metadata": {},
      "source": [
        "### Bonus Test: Tool Use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6a2ed0c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Router]  -> TOOL_USE Expert\n",
            "--------------------------------------------------\n",
            "[Tool Fetch] The current price of Bitcoin is $97,432.15 USD.\n",
            "\n",
            "[Router]  -> TOOL_USE Expert\n",
            "--------------------------------------------------\n",
            "[Tool Fetch] The current price of Ethereum is $3,521.80 USD.\n"
          ]
        }
      ],
      "source": [
        "time.sleep(2)\n",
        "_ = process_request_v2(\"What is the current price of Bitcoin?\")\n",
        "print()\n",
        "time.sleep(1)\n",
        "_ = process_request_v2(\"How much is Ethereum worth right now?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
